# OCR_intern

End-to-end OCR pipeline built during my internship at **Bedo Company**.  
The project digitizes text from hardcopy sources (Egyptian IDs dataset) using a combination of **computer vision preprocessing**, **deep learning models**, and structured **result exports**.

---

## ğŸš€ Features
- **Preprocessing with OpenCV**: grayscale conversion, thresholding, denoising.
- **OCR Models**: CNN-based recognition for structured text fields.
- **TFRecords Pipeline**: dataset preparation for TensorFlow training.
- **Evaluation Outputs**: CSV files (`ocr_results.csv`, `final_detected_faces.csv`) with recognized text.
- **Visualization**: sample images showing intermediate processing and final detection results.
- **Analysis Module**: accuracy metrics and error breakdown.

---

## ğŸ“‚ Project Structure
OCR/
â”‚â”€â”€ Analysis.py # metrics & evaluation
â”‚â”€â”€ OCR.py # main OCR pipeline
â”‚â”€â”€ OCRRRR.py # alternative OCR run
â”‚â”€â”€ Tf_DataSet.py # TFRecord dataset builder
â”‚â”€â”€ requirements.txt # dependencies
â”‚â”€â”€ outputs/ # predictions & logs (LFS)
â”‚â”€â”€ tfrecords/ # serialized data (LFS)
â”‚â”€â”€ final_detected_faces.csv # evaluation results
â”‚â”€â”€ ocr_results.csv # recognized text output
â”‚â”€â”€ Updated Data.xlsx # labeled dataset
â”‚â”€â”€ images/ # test samples




---

## âš™ï¸ Installation
```bash
# clone repo
git clone https://github.com/yousefselim1/OCR_intern.git
cd OCR_intern

# setup virtual environment
python -m venv .venv
.venv\Scripts\activate   # (Windows)
# source .venv/bin/activate   # (Linux/Mac)

# install dependencies
pip install -r requirements.txt


ğŸ–¼ï¸ Sample Results

Preprocessed input â†’ _debug_proc.png

Enhanced image â†’ _enh.png

Final recognized text saved in CSV outputs


ğŸ“Œ Requirements

Python 3.9+
TensorFlow / PyTorch
OpenCV
NumPy / Pandas

